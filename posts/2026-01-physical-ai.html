<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Why Iâ€™m Building Physical AI in 2026 â€“ June Hong</title>
    <link rel="stylesheet" href="../assets/style.css">
</head>
<body>

<nav>
    <a href="../aboutme.html">About Me</a>
    <a href="../blog.html">Blog</a>
</nav>

<article>
    <h1>ğŸ¤– Why Iâ€™m Building Physical AI in 2026</h1>
    <p><em>January 2026 Â· June Hong</em></p>

    <p>
        Over the past decade, AI has made incredible progress in the digital world â€”
        text, images, recommendations, and predictions. But in 2026, I believe the
        next real leap isnâ€™t just smarter models. Itâ€™s intelligence that can
        <strong>sense, decide, and act in the physical world</strong>.
    </p>

    <p>
        Thatâ€™s why Iâ€™m building Physical AI.
    </p>

    <h2>From Software to Systems</h2>
    <p>
        My background spans embedded systems, mobile platforms, cloud infrastructure,
        and machine learning. Iâ€™ve worked close to hardware â€” sensors, networks,
        real-time constraints â€” and Iâ€™ve also built scalable cloud services used by
        millions.
    </p>

    <p>
        One pattern keeps repeating: most AI systems stop at inference.
        They classify, predict, or generate â€” but someone else has to turn that output
        into action.
    </p>

    <p>
        Physical AI closes that loop.
    </p>

    <h2>What Physical AI Means to Me</h2>
    <p>
        Physical AI is not just robotics. Itâ€™s intelligence embedded into
        real-world systems:
    </p>

    <ul>
        <li>Devices that observe the environment through sensors</li>
        <li>Models that reason under latency, power, and reliability constraints</li>
        <li>Systems that take actions â€” not suggestions</li>
    </ul>

    <p>
        This includes edge devices, embedded Linux systems, MCUs, and hybrid
        cloudâ€“edge architectures. The challenge isnâ€™t only accuracy â€” itâ€™s
        robustness, timing, and safety.
    </p>

    <h2>Why Now?</h2>
    <p>
        Three things make 2026 the right moment:
    </p>

    <ul>
        <li>
            <strong>Edge hardware is ready</strong> â€” NPUs and accelerators are now
            practical outside data centers.
        </li>
        <li>
            <strong>ML tooling has matured</strong> â€” deployment, monitoring, and
            optimization are no longer research-only problems.
        </li>
        <li>
            <strong>Real-world systems demand intelligence</strong> â€” energy,
            manufacturing, mobility, and infrastructure all need smarter control.
        </li>
    </ul>

    <p>
        The gap between â€œAI demoâ€ and â€œAI systemâ€ is where most interesting work lives.
        That gap is exactly what I want to explore.
    </p>

    <h2>What Iâ€™m Building</h2>
    <p>
        My Physical AI projects focus on:
    </p>

    <ul>
        <li>Sensor fusion and real-time data pipelines</li>
        <li>Edge inference with cloud coordination</li>
        <li>Decision-making systems that operate continuously</li>
        <li>Integration with Digital Twins for simulation and prediction</li>
    </ul>

    <p>
        These projects are open, iterative, and built in public. Some will fail.
        Thatâ€™s part of the point.
    </p>

    <h2>What This Blog Is For</h2>
    <p>
        This blog is a working notebook â€” not marketing.
        Iâ€™ll document design decisions, experiments, mistakes, and lessons learned
        while building Physical AI systems.
    </p>

    <p>
        If youâ€™re interested in where AI meets hardware, systems engineering,
        and the real world, youâ€™re in t

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Understanding RAG: The Bridge Between LLMs and Your Data – June Hong</title>
  <meta name="description" content="Retrieval-Augmented Generation (RAG) is an architecture used to optimize the output of an LLM by referencing a trusted knowledge base outside of its training data.">
  <meta name="author" content="June Hong">

  <style>
    /* Global */
    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
      background-color: #f9fafb;
      color: #111827;
      line-height: 1.6;
    }

    a {
      color: #2563eb;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    /* Navigation */
    nav {
      position: sticky;
      top: 0;
      z-index: 10;
      background-color: rgba(249, 250, 251, 0.95);
      backdrop-filter: blur(8px);
      border-bottom: 1px solid #e5e7eb;
    }

    .nav-inner {
      max-width: 900px;
      margin: 0 auto;
      padding: 0.75rem 1.5rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .nav-brand {
      font-weight: 600;
      font-size: 1.1rem;
      display: flex;
      align-items: center;
      text-decoration: none;
      color: #111827;
    }
    
    .nav-brand:hover {
      text-decoration: none;
    }

    .monogram {
      display: flex;
      align-items: center;
      justify-content: center;
      width: 32px;
      height: 32px;
      background-color: #2563eb;
      color: white;
      border-radius: 6px;
      margin-right: 0.5rem;
      font-size: 0.9rem;
      font-weight: 700;
    }

    .nav-links a {
      margin-left: 1.5rem;
      font-size: 0.95rem;
      color: #374151;
      text-decoration: none;
    }

    .nav-links a:hover {
      color: #111827;
    }

    /* Article Header */
    header.article-header {
      padding: 4rem 1.5rem 2rem;
      max-width: 740px;
      margin: 0 auto;
      text-align: left;
    }

    .article-header h1 {
      font-size: 2.2rem;
      margin-bottom: 0.5rem;
      line-height: 1.3;
      color: #111827;
    }

    .article-meta {
      color: #6b7280;
      font-size: 0.95rem;
      margin-top: 1rem;
    }

    /* Main Content */
    main {
      max-width: 740px;
      margin: 0 auto;
      padding: 0 1.5rem 4rem;
    }

    article {
      font-size: 1.05rem;
      color: #374151;
    }

    article h2 {
      margin-top: 2.5rem;
      margin-bottom: 1rem;
      color: #111827;
      font-size: 1.5rem;
    }

    article h3 {
      margin-top: 2rem;
      margin-bottom: 0.75rem;
      color: #111827;
      font-size: 1.25rem;
    }

    article p {
      margin-bottom: 1.5rem;
    }

    article ul, article ol {
      margin-bottom: 1.5rem;
      padding-left: 1.5rem;
    }

    article li {
      margin-bottom: 0.5rem;
    }

    article blockquote {
      border-left: 4px solid #2563eb;
      margin: 1.5rem 0;
      padding-left: 1rem;
      font-style: italic;
      color: #4b5563;
      background-color: #eff6ff;
      padding: 1rem;
      border-radius: 0 0.5rem 0.5rem 0;
    }

    article img {
      max-width: 100%;
      height: auto;
      border-radius: 0.5rem;
      margin: 1.5rem 0;
    }
    
    article code {
      background-color: #f3f4f6;
      padding: 0.2rem 0.4rem;
      border-radius: 0.25rem;
      font-size: 0.9em;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
      color: #be185d;
    }

    article pre {
      background-color: #1f2937;
      color: #f9fafb;
      padding: 1rem;
      border-radius: 0.5rem;
      overflow-x: auto;
      margin: 1.5rem 0;
    }

    article pre code {
      background-color: transparent;
      color: inherit;
      padding: 0;
      font-size: 0.9em;
    }
    
    article table {
      width: 100%;
      border-collapse: collapse;
      margin: 1.5rem 0;
    }
    
    article th, article td {
      border: 1px solid #e5e7eb;
      padding: 0.75rem;
      text-align: left;
    }
    
    article th {
      background-color: #f9fafb;
      font-weight: 600;
    }

    /* Footer */
    footer {
      text-align: center;
      padding: 2rem 1rem;
      color: #6b7280;
      font-size: 0.9rem;
      border-top: 1px solid #e5e7eb;
      margin-top: 2rem;
    }
  </style>
</head>

<body>

  <!-- Navigation -->
  <nav>
    <div class="nav-inner">
      <a href="../index.html" class="nav-brand">
        <div class="monogram">JH</div>
        <span>June Hong</span>
      </a>
      <div class="nav-links">
        <a href="../index.html">Home</a>
        <a href="../blog.html">Blog</a>
        <a href="https://github.com/junehong-dominicus" target="_blank">GitHub</a>
        <a href="https://www.linkedin.com/in/junehong-dominicus/" target="_blank">LinkedIn</a>
      </div>
    </div>
  </nav>

  <!-- Article Header -->
  <header class="article-header">
    <h1>Understanding RAG: The Bridge Between LLMs and Your Data</h1>
    <div class="article-meta">
      By June Hong • <time>2026-01-11</time>
    </div>
  </header>

  <main>
    <article>
      <h1>Understanding RAG: The Bridge Between LLMs and Your Data</h1>
<p>Large Language Models (LLMs) like GPT-4 or Gemini are incredibly powerful, but they have two major limitations: they have a <strong>knowledge cutoff</strong> (they don't know what happened yesterday), and they don't have access to <strong>your private data</strong> (your company’s docs, your personal notes, etc.).</p>
<p>This is where <strong>Retrieval-Augmented Generation (RAG)</strong> comes in.</p>
<hr />
<h2>What is RAG?</h2>
<p><strong>Retrieval-Augmented Generation (RAG)</strong> is an architecture used to optimize the output of an LLM by referencing a trusted knowledge base outside of its training data before generating a response.</p>
<p>Think of it this way:</p>
<ul>
<li><strong>Standard LLM:</strong> Answering a history exam based purely on memory.</li>
<li><strong>RAG-enabled LLM:</strong> Answering a history exam with an open textbook tailored specifically to the subject.</li>
</ul>
<hr />
<h2>How RAG Works: A Step-by-Step Breakdown</h2>
<p>The RAG process can be broken down into two main phases: the <strong>Data Preparation</strong> phase and the <strong>Inference (Retrieval &amp; Generation)</strong> phase.</p>
<h3>1. Data Preparation (The Indexing Phase)</h3>
<p>Before you can ask questions, you have to make your data "readable" for the AI.</p>
<ul>
<li><strong>Loading:</strong> Importing documents (PDFs, HTML, Markdown).</li>
<li><strong>Chunking:</strong> Breaking long documents into smaller, manageable pieces.</li>
<li><strong>Embedding:</strong> Converting these text chunks into numerical vectors using an embedding model.</li>
<li><strong>Vector Store:</strong> Storing these vectors in a specialized database (like Pinecone, Milvus, or Weaviate).</li>
</ul>
<h3>2. The Retrieval &amp; Generation Loop</h3>
<p>When a user asks a question, the following happens in milliseconds:</p>
<ol>
<li><strong>Query Transformation:</strong> The user's question is converted into a vector.</li>
<li><strong>Retrieval:</strong> The system searches the Vector Store for the "chunks" of text that are mathematically most similar to the question.</li>
<li><strong>Augmentation:</strong> The system combines the original user question with the retrieved chunks into a single prompt.</li>
<li><strong>Generation:</strong> The LLM reads the provided context and answers the question accurately.</li>
</ol>
<hr />
<h2>Why Use RAG Instead of Fine-Tuning?</h2>
<p>A common question is: <em>"Why not just fine-tune the model on my data?"</em> While fine-tuning is great for teaching a model a specific <em>style</em> or <em>vocabulary</em>, RAG is usually superior for <em>facts</em>.</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>RAG</th>
<th>Fine-Tuning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Knowledge Update</strong></td>
<td>Instant (just add a new doc)</td>
<td>Slow (requires retraining)</td>
</tr>
<tr>
<td><strong>Transparency</strong></td>
<td>High (can cite sources)</td>
<td>Low (black box)</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>Low</td>
<td>High (GPU intensive)</td>
</tr>
<tr>
<td><strong>Hallucination</strong></td>
<td>Significantly Reduced</td>
<td>Still Possible</td>
</tr>
</tbody>
</table>
<hr />
<h2>The Benefits of RAG</h2>
<ul>
<li><strong>Accuracy:</strong> It grounds the model in factual, up-to-date information.</li>
<li><strong>Source Attribution:</strong> RAG systems can provide citations, allowing users to verify where the information came from.</li>
<li><strong>Data Privacy:</strong> You don't need to send your entire dataset to a model provider for training; you only send the relevant snippets during the prompt.</li>
</ul>
<hr />
<h2>Conclusion</h2>
<p>RAG is the gold standard for building AI applications that need to be reliable, factual, and specialized. By bridging the gap between a model's reasoning capabilities and your specific data, you turn a general-purpose AI into a powerful, domain-specific expert.</p>
    </article>
  </main>

  <footer>
    © 2025 June Hong — Built with plain HTML & CSS
  </footer>

</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Understanding RAG: The Bridge Between LLMs and Your Data – June Hong</title>
    <meta name="description" content="Retrieval-Augmented Generation (RAG) is an architecture used to optimize the output of an LLM by referencing a trusted knowledge base outside of its training data.">
    <link rel="stylesheet" href="../assets/style.css">
</head>
<body>

<nav>
    <a href="../aboutme.html">About Me</a>
    <a href="../blog.html">Blog</a>
</nav>

<article>
    <p><em>2026-01-11 · June Hong</em></p>

    <h1>Understanding RAG: The Bridge Between LLMs and Your Data</h1>
<p>Large Language Models (LLMs) like GPT-4 or Gemini are incredibly powerful, but they have two major limitations: they have a <strong>knowledge cutoff</strong> (they don't know what happened yesterday), and they don't have access to <strong>your private data</strong> (your company’s docs, your personal notes, etc.).</p>
<p>This is where <strong>Retrieval-Augmented Generation (RAG)</strong> comes in.</p>
<hr />
<h2>What is RAG?</h2>
<p><strong>Retrieval-Augmented Generation (RAG)</strong> is an architecture used to optimize the output of an LLM by referencing a trusted knowledge base outside of its training data before generating a response.</p>
<p>Think of it this way:</p>
<ul>
<li><strong>Standard LLM:</strong> Answering a history exam based purely on memory.</li>
<li><strong>RAG-enabled LLM:</strong> Answering a history exam with an open textbook tailored specifically to the subject.</li>
</ul>
<hr />
<h2>How RAG Works: A Step-by-Step Breakdown</h2>
<p>The RAG process can be broken down into two main phases: the <strong>Data Preparation</strong> phase and the <strong>Inference (Retrieval &amp; Generation)</strong> phase.</p>
<h3>1. Data Preparation (The Indexing Phase)</h3>
<p>Before you can ask questions, you have to make your data "readable" for the AI.</p>
<ul>
<li><strong>Loading:</strong> Importing documents (PDFs, HTML, Markdown).</li>
<li><strong>Chunking:</strong> Breaking long documents into smaller, manageable pieces.</li>
<li><strong>Embedding:</strong> Converting these text chunks into numerical vectors using an embedding model.</li>
<li><strong>Vector Store:</strong> Storing these vectors in a specialized database (like Pinecone, Milvus, or Weaviate).</li>
</ul>
<h3>2. The Retrieval &amp; Generation Loop</h3>
<p>When a user asks a question, the following happens in milliseconds:</p>
<ol>
<li><strong>Query Transformation:</strong> The user's question is converted into a vector.</li>
<li><strong>Retrieval:</strong> The system searches the Vector Store for the "chunks" of text that are mathematically most similar to the question.</li>
<li><strong>Augmentation:</strong> The system combines the original user question with the retrieved chunks into a single prompt.</li>
<li><strong>Generation:</strong> The LLM reads the provided context and answers the question accurately.</li>
</ol>
<hr />
<h2>Why Use RAG Instead of Fine-Tuning?</h2>
<p>A common question is: <em>"Why not just fine-tune the model on my data?"</em> While fine-tuning is great for teaching a model a specific <em>style</em> or <em>vocabulary</em>, RAG is usually superior for <em>facts</em>.</p>
<p>| Feature | RAG | Fine-Tuning |
| --- | --- | --- |
| <strong>Knowledge Update</strong> | Instant (just add a new doc) | Slow (requires retraining) |
| <strong>Transparency</strong> | High (can cite sources) | Low (black box) |
| <strong>Cost</strong> | Low | High (GPU intensive) |
| <strong>Hallucination</strong> | Significantly Reduced | Still Possible |</p>
<hr />
<h2>The Benefits of RAG</h2>
<ul>
<li><strong>Accuracy:</strong> It grounds the model in factual, up-to-date information.</li>
<li><strong>Source Attribution:</strong> RAG systems can provide citations, allowing users to verify where the information came from.</li>
<li><strong>Data Privacy:</strong> You don't need to send your entire dataset to a model provider for training; you only send the relevant snippets during the prompt.</li>
</ul>
<hr />
<h2>Conclusion</h2>
<p>RAG is the gold standard for building AI applications that need to be reliable, factual, and specialized. By bridging the gap between a model's reasoning capabilities and your specific data, you turn a general-purpose AI into a powerful, domain-specific expert.</p>
</article>

</body>
</html>
